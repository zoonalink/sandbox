{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Science from Scratch: Ch 14 - Simple Linear Regression\n",
    "\n",
    "use kernel / env - `dsfs`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(alpha: float, beta: float, x_i: float) -> float:\n",
    "    return beta * x_i + alpha\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def error(alpha: float, beta: float, x_i: float, y_i: float) -> float:\n",
    "    \"\"\"\n",
    "    The error from predicting beta * x_i + alpha\n",
    "    when the actual value is y_i\n",
    "    \"\"\"\n",
    "    return predict(alpha, beta, x_i) - y_i\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from scratch.linear_algebra import Vector\n",
    "\n",
    "def sum_of_sqerrors(alpha: float, beta: float, x: Vector, y: Vector) -> float:\n",
    "    return sum(error(alpha, beta, x_i, y_i) ** 2\n",
    "               for x_i, y_i in zip(x, y))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from typing import Tuple\n",
    "from scratch.linear_algebra import Vector\n",
    "from scratch.statistics import correlation, standard_deviation, mean\n",
    "\n",
    "def least_squares_fit(x: Vector, y: Vector) -> Tuple[float, float]:\n",
    "    \"\"\"\n",
    "    Given two vectors x and y,\n",
    "    find the least-squares values of alpha and beta\n",
    "    \"\"\"\n",
    "    beta = correlation(x, y) * standard_deviation(y) / standard_deviation(x)\n",
    "    alpha = mean(y) - beta * mean(x)\n",
    "    return alpha, beta\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "x = [i for i in range(-100, 110, 10)]\n",
    "y = [3 * i - 5 for i in x]\n",
    "\n",
    "# Should find that y = 3x - 5\n",
    "assert least_squares_fit(x, y) == (-5, 3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from scratch.statistics import num_friends_good, daily_minutes_good\n",
    "\n",
    "alpha, beta = least_squares_fit(num_friends_good, daily_minutes_good)\n",
    "assert 22.9 < alpha < 23.0\n",
    "assert 0.9 < beta < 0.905\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of course, we need a better way to figure out how well weâ€™ve fit the data than staring at the graph. A common measure is the coefficient of determination (or R-squared), which **measures the fraction of the total variation in the dependent variable that is captured by the model**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from scratch.statistics import de_mean\n",
    "\n",
    "def total_sum_of_squares(y: Vector) -> float:\n",
    "    \"\"\"the total squared variation of y_i's from their mean\"\"\"\n",
    "    return sum(v ** 2 for v in de_mean(y))\n",
    "\n",
    "def r_squared(alpha: float, beta: float, x: Vector, y: Vector) -> float:\n",
    "    \"\"\"\n",
    "    the fraction of variation in y captured by the model, which equals\n",
    "    1 - the fraction of variation in y not captured by the model\n",
    "    \"\"\"\n",
    "    return 1.0 - (sum_of_sqerrors(alpha, beta, x, y) /\n",
    "                  total_sum_of_squares(y))\n",
    "\n",
    "rsq = r_squared(alpha, beta, num_friends_good, daily_minutes_good)\n",
    "assert 0.328 < rsq < 0.330\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clearly, the least squares model must be at least as good as that one, which means that the sum of the squared errors is at most the total sum of squares, which means that the R-squared must be at least 0. And the sum of squared errors must be at least 0, which means that the R-squared can be at most 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def main():\n",
    "    import random\n",
    "    import tqdm\n",
    "    from scratch.gradient_descent import gradient_step\n",
    "    \n",
    "    num_epochs = 10000\n",
    "    random.seed(0)\n",
    "    \n",
    "    guess = [random.random(), random.random()]  # choose random value to start\n",
    "    \n",
    "    learning_rate = 0.00001\n",
    "    \n",
    "    with tqdm.trange(num_epochs) as t:\n",
    "        for _ in t:\n",
    "            alpha, beta = guess\n",
    "    \n",
    "            # Partial derivative of loss with respect to alpha\n",
    "            grad_a = sum(2 * error(alpha, beta, x_i, y_i)\n",
    "                         for x_i, y_i in zip(num_friends_good,\n",
    "                                             daily_minutes_good))\n",
    "    \n",
    "            # Partial derivative of loss with respect to beta\n",
    "            grad_b = sum(2 * error(alpha, beta, x_i, y_i) * x_i\n",
    "                         for x_i, y_i in zip(num_friends_good,\n",
    "                                             daily_minutes_good))\n",
    "    \n",
    "            # Compute loss to stick in the tqdm description\n",
    "            loss = sum_of_sqerrors(alpha, beta,\n",
    "                                   num_friends_good, daily_minutes_good)\n",
    "            t.set_description(f\"loss: {loss:.3f}\")\n",
    "    \n",
    "            # Finally, update the guess\n",
    "            guess = gradient_step(guess, [grad_a, grad_b], -learning_rate)\n",
    "    \n",
    "    # We should get pretty much the same results:\n",
    "    alpha, beta = guess\n",
    "    assert 22.9 < alpha < 23.0\n",
    "    assert 0.9 < beta < 0.905\n",
    "    \n",
    "if __name__ == \"__main__\": main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dsfs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.6.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
